{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection\n",
    "\n",
    "#### _Face detection is a computer technology being used in a variety of applications that identifies human faces in digital images_\n",
    "\n",
    "\n",
    "> In the below file we will look at different ways in which we can Detect Faces in any image / real time using webcam\n",
    "\n",
    ">Haarcascades for face detection\n",
    "\n",
    ">Using Face recognition library for face detection\n",
    "\n",
    ">Pre trained neural network for face detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with Haarcascades for face detection.\n",
    "Lets have a brief description what haarcascades are and how could they detect faces in an image \n",
    "\n",
    "Haar Cascade is a machine learning object detection algorithm used to identify objects in an image or video\n",
    "and based on the concept of features .\n",
    "\n",
    "When it comes to using Haarcascade for face detection , its basically learning different haar features from the image being passed.\n",
    "And using the haar features and already built classifier we are being able to detect if its a face or not.\n",
    "\n",
    "[Click Here for More details](http://www.willberger.org/cascade-haar-explained/)\n",
    "\n",
    "Lets get started:\n",
    "Make sure you have downloaded the haarcascade_frontalface_default.xml (Attached in data folder )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets take an input image and check if it has a face or not\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_default.xml')\n",
    "\n",
    "img=cv2.imread(\"data/baby.PNG\")\n",
    "#gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = img[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    \n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face detection using web cam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "face_detector = cv2.CascadeClassifier('data/haarcascade_frontalface_default.xml')\n",
    "\n",
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    faces = face_detector.detectMultiScale(img, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        x1 = x\n",
    "        y1 = y\n",
    "        x2 = x+w\n",
    "        y2 = y+h\n",
    "        cv2.rectangle(img, (x1,y1), (x2,y2), (255,255,255), 2)     \n",
    "    k = cv2.waitKey(200) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Face_Recognition Library for detecting faces \n",
    "Before going ahead use pip install face_recognition\n",
    "There may be issues while downloading the above library (download cmake , dlib , download Visual studio as per the steps in the below .\n",
    "\n",
    "\n",
    "\n",
    "Follow these steps:\n",
    "\n",
    "> * pip install cmake\n",
    "* Install Visual Studio build tools from here.\n",
    "* In Visual Studio 2017 go to the Individual Components tab, Visual C++ Tools for Cmake, and check the checkbox under the \"Compilers, build tools and runtimes\" section.\n",
    "* pip install dlib\n",
    "\n",
    "It will work definitely but do keep patience.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once installed Lets get started\n",
    "import cv2\n",
    "import face_recognition\n",
    "img = face_recognition.load_image_file(\"data/baby.PNG\")#\"your_file.jpg\")\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "for face_loc in face_locations:\n",
    "    top, right, bottom, left = face_loc\n",
    "    img = cv2.rectangle(img, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "   \n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face detection using web cam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    face_locations = face_recognition.face_locations(img)\n",
    "\n",
    "    # Display the results\n",
    "    for top, right, bottom, left in face_locations:\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Image', img)     \n",
    "    k = cv2.waitKey(200) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pre-trained caffe model for face detection\n",
    "\n",
    ">Make sure you have downloaded the below files\n",
    "* The .prototxt file(s) which define the model architecture (i.e., the layers themselves)\n",
    "* The .caffemodel file which contains the weights for the actual layers\n",
    "\n",
    "(Already placed inside data folder)\n",
    "\n",
    "    \n",
    "The below code being used is what I learnt from the below link:\n",
    "    [Click Here ](https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "from imutils.video import FPS\n",
    "import imutils\n",
    "import time\n",
    "\n",
    "net1 = cv2.dnn.readNetFromCaffe(\"data/deploy.prototxt.txt\",\n",
    "                               \"data/res10_300x300_ssd_iter_140000.caffemodel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"data/baby.PNG\")\n",
    "\n",
    "img = imutils.resize(img, width=800)\n",
    "# grab the frame dimensions and convert it to a blob\n",
    "(h, w) = img.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(cv2.resize(img, (600, 600)), 1.0,\n",
    "            (600, 600), (104.0, 177.0, 123.0))\n",
    "\n",
    "#pass the blob through the network and obtain the detections and predictions\n",
    "net1.setInput(blob)\n",
    "detections = net1.forward()\n",
    "\n",
    "# loop over the detections\n",
    "for i in range(0, detections.shape[2]):\n",
    "    # extract the confidence (i.e., probability) associated with the prediction\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    # filter out weak detections by ensuring the `confidence` is\n",
    "    # greater than the minimum confidence\n",
    "    if confidence < 0.5:\n",
    "        continue\n",
    "\n",
    "    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\n",
    "    cv2.rectangle(img,(startX,startY),(endX,endY),(255,0,0),2) #draw rectangle to main image\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face detection using web cam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    img = imutils.resize(img, width=800)\n",
    "\n",
    "    # grab the frame dimensions and convert it to a blob\n",
    "    (h, w) = img.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(img, (600, 600)), 1.0,\n",
    "            (600, 600), (104.0, 177.0, 123.0))\n",
    "\n",
    "    # pass the blob through the network and obtain the detections and\n",
    "    # predictions\n",
    "    net1.setInput(blob)\n",
    "    detections = net1.forward()\n",
    "\n",
    "    # loop over the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with the\n",
    "        # prediction\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # filter out weak detections by ensuring the `confidence` is\n",
    "        # greater than the minimum confidence\n",
    "        if confidence < 0.5:\n",
    "            continue\n",
    "\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        \n",
    "        cv2.rectangle(img,(startX,startY),(endX,endY),(255,0,0),2) #draw rectangle to main image\n",
    "\n",
    "\n",
    "    cv2.imshow('Image', img)     \n",
    "    k = cv2.waitKey(200) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
